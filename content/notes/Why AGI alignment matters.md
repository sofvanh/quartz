---
title: "Why AI alignment matters"
date: "2022-08-03"
tags:
- wip
- learning
- alignment
---

## The view of MIRI / Nate Soares

1. Humans have a very general ability to solve problems and achieve goals across diverse domains.
2. AI systems could become much more intelligent than humans.
3. If we create highly intelligent AI systems, their decisions will shape the future.
4. Highly intelligent AI systems wonâ€™t be beneficial by default.

[Source](https://intelligence.org/2015/07/24/four-background-claims/)

## Forming your own view

See [[notes/Modeling AGI timelines with anchors|Modeling AGI timelines with anchors]]

## Further action

See [[notes/How to help with aligning AI|How to help with aligning AI]]