<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Notes on</title><link>https://sofvanh.github.io/quartz/notes/</link><description>Recent content in Notes on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 03 Aug 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://sofvanh.github.io/quartz/notes/index.xml" rel="self" type="application/rss+xml"/><item><title>How to help with aligning AI</title><link>https://sofvanh.github.io/quartz/notes/How-to-help-with-aligning-AI/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://sofvanh.github.io/quartz/notes/How-to-help-with-aligning-AI/</guid><description> Nonlinear&amp;rsquo;s list of resources How to pursue a career in technical AI alignment by Charlie Rogers-Smith AI safety ideas</description></item><item><title>Inadequacy</title><link>https://sofvanh.github.io/quartz/notes/Inadequacy/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://sofvanh.github.io/quartz/notes/Inadequacy/</guid><description>&amp;ldquo;I am completely inept and inadequate at all the things I&amp;rsquo;m trying to do.&amp;rdquo;
That&amp;rsquo;s a thought I had a few days ago.</description></item><item><title>Why AI alignment matters</title><link>https://sofvanh.github.io/quartz/notes/Why-AGI-alignment-matters/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://sofvanh.github.io/quartz/notes/Why-AGI-alignment-matters/</guid><description>The view of MIRI / Nate Soares Humans have a very general ability to solve problems and achieve goals across diverse domains.</description></item><item><title>Modeling AGI timelines with anchors</title><link>https://sofvanh.github.io/quartz/notes/Modeling-AGI-timelines-with-anchors/</link><pubDate>Fri, 29 Jul 2022 00:00:00 +0000</pubDate><guid>https://sofvanh.github.io/quartz/notes/Modeling-AGI-timelines-with-anchors/</guid><description>Modeling = creating a &amp;ldquo;mental model&amp;rdquo; or thinking with a framework
AGI = artificial general intelligence
AGI timeline = the expected time until AGI is developed</description></item><item><title>Digital gardens</title><link>https://sofvanh.github.io/quartz/notes/Digital-gardens/</link><pubDate>Thu, 28 Jul 2022 00:00:00 +0000</pubDate><guid>https://sofvanh.github.io/quartz/notes/Digital-gardens/</guid><description>I recently came across a bunch of websites doing something interesting: People are sharing their personal notes (often Obsidian vaults), or a curated collection of them, publicly on the internet, on their own websites.</description></item></channel></rss>