<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>wip on</title><link>https://sofvanh.github.io/quartz/tags/wip/</link><description>Recent content in wip on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 03 Aug 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://sofvanh.github.io/quartz/tags/wip/index.xml" rel="self" type="application/rss+xml"/><item><title>Why AI alignment matters</title><link>https://sofvanh.github.io/quartz/notes/Why-AGI-alignment-matters/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://sofvanh.github.io/quartz/notes/Why-AGI-alignment-matters/</guid><description>The view of MIRI / Nate Soares Humans have a very general ability to solve problems and achieve goals across diverse domains.</description></item><item><title>Modeling AGI timelines with anchors</title><link>https://sofvanh.github.io/quartz/notes/Modeling-AGI-timelines-with-anchors/</link><pubDate>Fri, 29 Jul 2022 00:00:00 +0000</pubDate><guid>https://sofvanh.github.io/quartz/notes/Modeling-AGI-timelines-with-anchors/</guid><description>Modeling = creating a &amp;ldquo;mental model&amp;rdquo; or thinking with a framework
AGI = artificial general intelligence
AGI timeline = the expected time until AGI is developed</description></item></channel></rss>