<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>wip on</title><link>https://sofvanh.github.io/quartz/tags/wip/</link><description>Recent content in wip on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 14 Aug 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://sofvanh.github.io/quartz/tags/wip/index.xml" rel="self" type="application/rss+xml"/><item><title>Why 'aligning' AI matters</title><link>https://sofvanh.github.io/quartz/notes/Why-aligning-AI-matters/</link><pubDate>Sun, 14 Aug 2022 00:00:00 +0000</pubDate><guid>https://sofvanh.github.io/quartz/notes/Why-aligning-AI-matters/</guid><description>Humans are smart, machines could be even smarter, super-smart machines means big changes, and those changes might not be good.</description></item></channel></rss>